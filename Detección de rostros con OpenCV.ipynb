{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección del rostro y facciones con OpenCV y Haarcascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar OpenCV y Haarcascades para la detección de rostros en python. Lo haremos en tiempo real, utilizando nuestra propia webcam.\n",
    "\n",
    "OpenCV es una librería muy potente de visión por computador o visión artificial que nació en los laboratorios de Intel. Para la detección de los rostros haremos uso de Haarcascades preentrenados para la tarea. Estos clasificadores preenterandos fundcionan mediante una combinación de clasificadores especializados en las diferentes características del rostro. Para la detección de facciones haremo suso de dlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notas importantes_: \n",
    "* Si en vez de pulsar \"q\" cierras la ventana de la webcam clickando en la X, tendrás que reiniciar el Kernel. Esto es debido a cómo funcionan tanto Jupyter como la captura de video de la webcam.\n",
    "* Siempre ejecuta tanto el bloque de inicialización del entorno y luego, el de procesado de imagen u opencv dará error.\n",
    "* Hay una linea para reducir el tamaño de la imagen que captura la webcam. Esta comentada por defecto. Esto es otra técnica de optimización que en mi caso, no hace falta porque mi webcam tiene la resolución de una GameBoy, pero puede que en vuestro caso sí lo sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib  \n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import canny\n",
    "from skimage import exposure\n",
    "\n",
    "# cargamos los datos necesarios de los clasificadores preentrenados\n",
    "cascade_path = \"./haarcascades/haarcascade_frontalface_default.xml\"\n",
    "predictor_path = \"./pred/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# cargamos los clasificadores de detección de rostro y facciones faciales\n",
    "faceCascade = cv2.CascadeClassifier(cascade_path)\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# inicializamos la captura de webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "draw_points = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, este notebook hace dos cosas: detectar rostros e identificar las facciones de la cara.\n",
    "\n",
    "Detectar las facciones es algo costoso para hacerlo en tiempo real, pero con una pequeña técnica de optimización se puede conseguir. Lo que hacemos una vez detectado el rostro es establecer un área de trabajo para detectar las facciones de dicho rostro y no tener que buscarlos por toda la imagen capturada. Estamos indicando al detector de facciones dónde está la cara exactamente para tener que procesar menos datos.\n",
    "\n",
    "La forma en la que funciona, a grosso modo es la siguiente:\n",
    "\n",
    "* Tendremos un bucle infinito que seguirá capturando desde la webcam hasta que pulsemos la letra \"q\". ¡Acuérdate de esto para cerrar la captura o tendrás que reiniciar el Kernel!\n",
    "* Para cada frame que capturamos de la webcam:\n",
    "    * Convertimos a blanco y negro.\n",
    "    * Ecualizamos (si es necesario...)\n",
    "    * Suavizamos (si es necesario...)\n",
    "    * Detectamos los rostros en la imagen en blanco y negro y filtrada\n",
    "    \n",
    "    * Para cada rostro detectado en la imagen:\n",
    "        * Establecemos un area rectangular donde buscar las facciones.\n",
    "        * Le damos ese area a dlib para que encuentre dichas facciones.\n",
    "        * Pintamos las facciones sobre el frame capturado en color.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle infinito de captura ¡Pulsa \"q\" en tu teclado para cancelarlo y apagar la webcam!\n",
    "while(True):\n",
    "    # Capturamos el frame\n",
    "    ret, frame = cap.read()\n",
    "    # Redimensionamos a tamaño 800 x 600 píxeles.\n",
    "    # frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Operamos sobre nuestro frame capturado: aquí puedes probar varias cosas!   \n",
    "    # Convertimos a blanco y negro\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Ecualizamos la imagen, la técnica que ya vimos en el worksheet\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    # suavizamos la imagen, esto puede no ser necesario e incluso empeorar los resultados\n",
    "    gray = cv2.bilateralFilter(gray,9,75,75)\n",
    "    \n",
    "    # filtered = sobel(gray)\n",
    "    # filtered = exposure.equalize_hist(gray)\n",
    "    # filtered = exposure.equalize_adapthist(gray, clip_limit=0.5)\n",
    "    # cv2.imshow('frame', filtered)\n",
    "    # Buscamos rostros en la imagen capturada\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "            frame,\n",
    "            scaleFactor = 1.3,\n",
    "            minNeighbors = 4,\n",
    "            minSize = (100,100),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "    \n",
    "    # Para cada rostro detectado en la imagen...\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Dibujamos un rectángulo indicando el área de dicha imagen\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Establecemos un área de trabajo para detectar las facciones en el rostro actual\n",
    "        dlib_rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h)) \n",
    "        detected_landmarks = predictor(gray, dlib_rect).parts()\n",
    "        \n",
    "        # Pintamos las facciones\n",
    "        landmarks = np.matrix([[p.x, p.y] for p in detected_landmarks])\n",
    "        if draw_points:\n",
    "            for idx, point in enumerate(landmarks):\n",
    "                pos = (point[0, 0], point[0, 1])  \n",
    "\n",
    "                # Anotamos las facciones\n",
    "                cv2.putText(frame, str(idx), pos,  \n",
    "                       fontFace=cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                       fontScale=0.4,  \n",
    "                       color=(0, 0, 255))  \n",
    "\n",
    "                # Dibujamos los puntos detectados de las facciones\n",
    "                cv2.circle(frame, pos, 1, color=(0, 255, 255))\n",
    "\n",
    "    # Pintamos el frame resultante\n",
    "    #cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Si pulsamos q, se cierra el bucle\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Se libera y cierra la captura de webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiésemos simplemente aplicar algún filtro de los vistos en el worksheet con scikit-image a la imagen capturada de la webcam, podríamos hacerlo con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib  \n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import canny\n",
    "from skimage import exposure\n",
    "\n",
    "# inicializamos la captura de webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "draw_points = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle infinito de captura ¡Pulsa \"q\" en tu teclado para cancelarlo y apagar la webcam!\n",
    "while(True):\n",
    "    # Capturamos el frame\n",
    "    ret, frame = cap.read()\n",
    "    # Redimensionamos a tamaño 800 x 600 píxeles.\n",
    "    # frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Operamos sobre nuestro frame capturado: aquí puedes probar varias cosas!\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    filtered = sobel(gray)\n",
    "    #filtered = exposure.equalize_hist(gray)\n",
    "    #filtered = exposure.equalize_adapthist(gray, clip_limit=0.5)\n",
    "    #filtered = exposure.equalize_adapthist(filtered, clip_limit=0.5)\n",
    "    \n",
    "    # Pintamos el frame resultante\n",
    "    cv2.imshow('frame', filtered)\n",
    "    \n",
    "    # Si pulsamos q, se cierra el bucle\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Se libera y cierra la captura de webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
